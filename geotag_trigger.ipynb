{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458978ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dda1cacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] ID 1 @ (25.2624509, 82.9840395)\n",
      "[SAVED] ID 4 @ (25.2624509, 82.9838624)\n",
      "[SAVED] ID 6 @ (25.2624509, 82.9840395)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ===================== PATHS =====================\n",
    "# VIDEO_PATH = r\"F:\\New folder\\video_20260111_144158 - Trim - Trim.mp4\"\n",
    "MODEL_PATH = r\"E:\\NIDAR\\runs\\detect\\human_detection_y8n_stage22\\weights\\best.pt\"\n",
    "\n",
    "SAVE_DIR = \"detections\"\n",
    "IMG_DIR = os.path.join(SAVE_DIR, \"images\")\n",
    "CSV_PATH = os.path.join(SAVE_DIR, \"final_human_coordinates.csv\")\n",
    "os.makedirs(IMG_DIR, exist_ok=True)\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# ===================== CAMERA CALIBRATION =====================\n",
    "CAMERA_MATRIX = np.array([\n",
    "    [1176.58,    0.0,  999.32],\n",
    "    [   0.0, 1176.61,  522.03],\n",
    "    [   0.0,    0.0,     1.0]\n",
    "], dtype=np.float64)\n",
    "\n",
    "DIST_COEFFS = np.array([\n",
    "    0.25010672,\n",
    "   -0.53448585,\n",
    "   -0.01314542,\n",
    "    0.01928691,\n",
    "    0.4317226\n",
    "], dtype=np.float64)\n",
    "\n",
    "fx = CAMERA_MATRIX[0, 0]\n",
    "fy = CAMERA_MATRIX[1, 1]\n",
    "cx0 = CAMERA_MATRIX[0, 2]\n",
    "cy0 = CAMERA_MATRIX[1, 2]\n",
    "\n",
    "# ===================== PARAMETERS =====================\n",
    "PERSON_CLASS_ID = 0\n",
    "CONF_TH = 0.5\n",
    "\n",
    "BOTTOM_RATIO = 0.5          # bottom 40%\n",
    "CENTER_LEFT_RATIO = 0.3\n",
    "CENTER_RIGHT_RATIO = 0.7\n",
    "\n",
    "CAM_PITCH = math.radians(35)   # 35¬∞ downward from horizontal\n",
    "\n",
    "# ===================== HARDCODED DRONE STATE =====================\n",
    "DRONE_LAT = 25.2621092\n",
    "DRONE_LON = 82.9840395\n",
    "DRONE_ALT = 15.0   # meters AGL\n",
    "\n",
    "# ===================== CSV INIT =====================\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    with open(CSV_PATH, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"timestamp\", \"person_id\", \"human_lat\", \"human_lon\"])\n",
    "\n",
    "# ===================== MODEL & VIDEO =====================\n",
    "model = YOLO(MODEL_PATH)\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "logged_person_ids = set()\n",
    "\n",
    "# ===================== MAIN LOOP =====================\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Undistort frame\n",
    "    frame = cv2.undistort(frame, CAMERA_MATRIX, DIST_COEFFS)\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    bottom_limit = int(BOTTOM_RATIO * h)\n",
    "\n",
    "    results = model.track(\n",
    "        frame,\n",
    "        conf=CONF_TH,\n",
    "        persist=True,\n",
    "        verbose=False\n",
    "    )[0]\n",
    "\n",
    "    if results.boxes is None:\n",
    "        cv2.imshow(\"Detection\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "        continue\n",
    "\n",
    "    for box in results.boxes:\n",
    "\n",
    "        if int(box.cls[0]) != PERSON_CLASS_ID:\n",
    "            continue\n",
    "\n",
    "        if box.id is None:\n",
    "            continue\n",
    "\n",
    "        person_id = int(box.id[0])\n",
    "\n",
    "        if person_id in logged_person_ids:\n",
    "            continue\n",
    "\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        u = (x1 + x2) / 2\n",
    "        v = (y1 + y2) / 2\n",
    "\n",
    "        # -------- Bottom 40% filter --------\n",
    "        if v < bottom_limit:\n",
    "            continue\n",
    "\n",
    "        # -------- Clamp horizontal offset --------\n",
    "        center_left_px = CENTER_LEFT_RATIO * w\n",
    "        center_right_px = CENTER_RIGHT_RATIO * w\n",
    "\n",
    "        if center_left_px < u < center_right_px:\n",
    "            u_used = cx0\n",
    "        elif u <= center_left_px:\n",
    "            u_used = center_left_px\n",
    "        else:\n",
    "            u_used = center_right_px\n",
    "\n",
    "        v_used = bottom_limit\n",
    "\n",
    "        # -------- Pixel ‚Üí angles --------\n",
    "        theta_x = math.atan((u_used - cx0) / fx)\n",
    "        theta_y = math.atan((v_used - cy0) / fy)\n",
    "\n",
    "        # -------- Ground intersection --------\n",
    "        ground_angle = CAM_PITCH + theta_y\n",
    "        if ground_angle <= 0:\n",
    "            continue\n",
    "\n",
    "        forward_dist = DRONE_ALT / math.tan(ground_angle)\n",
    "        lateral_dist = forward_dist * math.tan(theta_x)\n",
    "\n",
    "        # -------- Global GPS --------\n",
    "        R_earth = 6378137.0\n",
    "        delta_lat = (forward_dist / R_earth) * (180 / math.pi)\n",
    "        delta_lon = (lateral_dist / (R_earth * math.cos(math.radians(DRONE_LAT)))) * (180 / math.pi)\n",
    "\n",
    "        human_lat = DRONE_LAT + delta_lat\n",
    "        human_lon = DRONE_LON + delta_lon\n",
    "\n",
    "        # -------- Save image --------\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        img_path = os.path.join(\n",
    "            IMG_DIR, f\"human_id{person_id}_{timestamp}.jpg\"\n",
    "        )\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            f\"ID:{person_id}\",\n",
    "            (x1, y1 - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.6,\n",
    "            (0, 255, 0),\n",
    "            2\n",
    "        )\n",
    "\n",
    "        cv2.imwrite(img_path, frame)\n",
    "\n",
    "        # -------- Save CSV --------\n",
    "        with open(CSV_PATH, \"a\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                timestamp,\n",
    "                person_id,\n",
    "                round(human_lat, 7),\n",
    "                round(human_lon, 7)\n",
    "            ])\n",
    "\n",
    "        logged_person_ids.add(person_id)\n",
    "        print(f\"[SAVED] ID {person_id} @ ({human_lat:.7f}, {human_lon:.7f})\")\n",
    "\n",
    "    # -------- Visual guides --------\n",
    "    cv2.line(frame, (0, bottom_limit), (w, bottom_limit), (0, 0, 255), 2)\n",
    "    cv2.line(frame, (int(CENTER_LEFT_RATIO * w), 0), (int(CENTER_LEFT_RATIO * w), h), (255, 255, 0), 1)\n",
    "    cv2.line(frame, (int(CENTER_RIGHT_RATIO * w), 0), (int(CENTER_RIGHT_RATIO * w), h), (255, 255, 0), 1)\n",
    "\n",
    "    cv2.imshow(\"Human Detection (Near-Only)\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041a171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import csv\n",
    "from geopy.distance import geodesic\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from collections import deque\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de82429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drone GPS \n",
    "drone_lon = 82.9840395\n",
    "drone_lat = 25.2621092\n",
    "drone_alt = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88847f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drone IMU\n",
    "imu_roll = 0.0\n",
    "imu_pitch = 0.0\n",
    "imu_yaw = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09953033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gimbal oriantation\n",
    "gimbal_roll = 0\n",
    "gimbal_pitch = -35\n",
    "gimbal_yaw =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5512f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert camera details into matrix form (roll, pitch and yaw are in radians)\n",
    "def R_x(a):\n",
    "    ca, sa = math.cos(a), math.sin(a)\n",
    "    return np.array([\n",
    "        [1, 0, 0],\n",
    "        [0, ca, -sa],\n",
    "        [0, sa,  ca]\n",
    "    ])\n",
    "\n",
    "def R_y(a):\n",
    "    ca, sa = math.cos(a), math.sin(a)\n",
    "    return np.array([\n",
    "        [ ca, 0, sa],\n",
    "        [  0, 1,  0],\n",
    "        [-sa, 0, ca]\n",
    "    ])\n",
    "\n",
    "def R_z(a):\n",
    "    ca, sa = math.cos(a), math.sin(a)\n",
    "    return np.array([\n",
    "        [ca, -sa, 0],\n",
    "        [sa,  ca, 0],\n",
    "        [ 0,   0, 1]\n",
    "    ])\n",
    "\n",
    "def get_camera_to_world_rotation(imu_roll, imu_pitch, imu_yaw, gimbal_pitch):\n",
    "    \n",
    "    # All angles in RADIANS\n",
    "    # imu_     : drone body attitude (from MAVLink ATTITUDE)\n",
    "    # gimbal_  : camera gimbal angles\n",
    "    \n",
    "    # Camera -> Gimbal\n",
    "    # Camera optical axis (Z forward) ‚Üí  Drone body forward (X)\n",
    "    R_cam_gimbal = np.array([\n",
    "        [ 0,  1,  0],\n",
    "        [ 1,  0,  0],\n",
    "        [ 0,  0, -1]\n",
    "    ])\n",
    "    # Gimbal -> Body \n",
    "    R_gimbal_body = (\n",
    "        R_y(gimbal_pitch) \n",
    "    )\n",
    "\n",
    "    # Body -> World \n",
    "    R_body_world = (\n",
    "        R_z(imu_yaw) @\n",
    "        R_y(imu_pitch) @\n",
    "        R_x(imu_roll)\n",
    "    )\n",
    "\n",
    "    # Final rotation matrix\n",
    "    return R_body_world @ R_gimbal_body @ R_cam_gimbal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7759638",
   "metadata": {},
   "outputs": [],
   "source": [
    "CALIB_WIDTH = 1920\n",
    "CALIB_HEIGHT = 1080\n",
    "\n",
    "def scale_camera_matrix(CAMERA_MATRIX, w, h):\n",
    "    sx = w / CALIB_WIDTH\n",
    "    sy = h / CALIB_HEIGHT\n",
    "\n",
    "    K_scaled = CAMERA_MATRIX.copy()\n",
    "    K_scaled[0, 0] *= sx   # fx\n",
    "    K_scaled[1, 1] *= sy   # fy\n",
    "    K_scaled[0, 2] *= sx   # cx\n",
    "    K_scaled[1, 2] *= sy   # cy\n",
    "\n",
    "    return K_scaled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aece8b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callibrated\n",
    "CAMERA_MATRIX = np.array([\n",
    "    [1176.58,    0.0,  999.32],\n",
    "    [   0.0,  1176.61, 522.03],\n",
    "    [   0.0,     0.0,    1.0]\n",
    "])\n",
    "\n",
    "DIST_COEFFS = np.array([\n",
    "    0.25010672,\n",
    "   -0.53448585,\n",
    "   -0.01314542,\n",
    "    0.01928691,\n",
    "    0.4317226\n",
    "])\n",
    "\n",
    "def get_geotag(\n",
    "    bbox,\n",
    "    frame,\n",
    "    drone_lat, drone_lon, drone_alt,\n",
    "    imu_roll, imu_pitch, imu_yaw,\n",
    "    gimbal_pitch\n",
    "):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    u = (x1 + x2) * 0.5\n",
    "    v = y2 \n",
    "    \n",
    "    K = scale_camera_matrix(CAMERA_MATRIX, frame.shape[1], frame.shape[0])\n",
    "    # Undistort the POINT (u, v)\n",
    "    pts = np.array([[[u, v]]], dtype=np.float32)\n",
    "\n",
    "    pts_undist = cv2.undistortPoints(\n",
    "        pts,\n",
    "        CAMERA_MATRIX,\n",
    "        DIST_COEFFS,\n",
    "        P=K        # returns pixel coordinates\n",
    "    )\n",
    "\n",
    "    u_undist, v_undist = pts_undist[0, 0]\n",
    "    \n",
    "\n",
    "\n",
    "    fx = K[0, 0]\n",
    "    fy = K[1, 1]\n",
    "    cx = K[0, 2]\n",
    "    cy = K[1, 2]\n",
    "\n",
    "\n",
    "    # Pixel ‚Üí camera ray\n",
    "    x_cam = (u_undist - cx) / fx\n",
    "    y_cam = -(v_undist - cy) / fy\n",
    "    z_cam = -1.0\n",
    "\n",
    "    ray_cam = np.array([x_cam, y_cam, z_cam])\n",
    "    ray_cam /= np.linalg.norm(ray_cam)\n",
    "\n",
    "    # Rotations\n",
    "    roll  = math.radians(imu_roll)\n",
    "    pitch = math.radians(imu_pitch + gimbal_pitch)\n",
    "    yaw   = math.radians(imu_yaw)\n",
    "\n",
    "    Rz = np.array([\n",
    "        [ math.cos(yaw), -math.sin(yaw), 0],\n",
    "        [ math.sin(yaw),  math.cos(yaw), 0],\n",
    "        [ 0,              0,             1]\n",
    "    ])\n",
    "\n",
    "    Ry = np.array([\n",
    "        [ math.cos(pitch), 0, math.sin(pitch)],\n",
    "        [ 0,               1, 0],\n",
    "        [-math.sin(pitch), 0, math.cos(pitch)]\n",
    "    ])\n",
    "\n",
    "    Rx = np.array([\n",
    "        [1, 0,              0],\n",
    "        [0, math.cos(roll), -math.sin(roll)],\n",
    "        [0, math.sin(roll),  math.cos(roll)]\n",
    "    ])\n",
    "\n",
    "    R = Rz @ Ry @ Rx\n",
    "    ray_world = R @ ray_cam\n",
    "\n",
    "    if ray_world[2] >= -1e-6:\n",
    "        return None\n",
    "\n",
    "    t = drone_alt /(-ray_world[2])\n",
    "    east  = t * ray_world[0]\n",
    "    north = t * ray_world[1]\n",
    "\n",
    "    R_earth = 6378137.0\n",
    "\n",
    "    dlat = (north / R_earth) * (180 / math.pi)\n",
    "    dlon = (east  / (R_earth * math.cos(math.radians(drone_lat)))) * (180 / math.pi)\n",
    "\n",
    "\n",
    "    return drone_lat + dlat, drone_lon + dlon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8808a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop(lat, lon):\n",
    "    print(f\"üöë DROPPING PARCEL at {lat}, {lon}\")\n",
    "\n",
    "\n",
    "\n",
    "def surveillance():\n",
    "    print(\"üõ∞Ô∏è SURVEILLANCE MODE\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2993dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanGPS:\n",
    "    def __init__(self, lat, lon):\n",
    "        self.x = np.array([[lat], [lon]])\n",
    "        self.P = np.eye(2) * 1e-4\n",
    "        self.Q = np.eye(2) * 1e-6\n",
    "        self.R = np.eye(2) * 1e-5\n",
    "\n",
    "    def update(self, lat, lon):\n",
    "        z = np.array([[lat], [lon]])\n",
    "        self.P = self.P + self.Q\n",
    "        K = self.P @ np.linalg.inv(self.P + self.R)\n",
    "        self.x = self.x + K @ (z - self.x)\n",
    "        self.P = (np.eye(2) - K) @ self.P\n",
    "        return float(self.x[0]), float(self.x[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25be614",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSON_CLASS_ID = 0\n",
    "CONF_TH = 0.50\n",
    "FRAME_CONFIRM = 10         \n",
    "SERVE_RADIUS = 1     \n",
    "SAME_PERSON_RADIUS = 1\n",
    "AVG_WINDOW = 10 \n",
    "      \n",
    "\n",
    "#rtsp_url = \"rtsp://192.168.144.25:8554/main.264\"\n",
    "# rtsp_url = r\"F:\\New folder\\video_20260111_144158 - Trim.mp4\"\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "# cap = cv2.VideoCapture(r\"E:\\NIDAR\\test\\final\\WhatsApp Video 2025-12-17 at 12.29.52.mp4\")\n",
    "model = YOLO(r\"E:\\NIDAR\\runs\\detect\\human_detection_y8n_stage22\\weights\\best.pt\")\n",
    "\n",
    "served_targets = []            \n",
    "candidate_tracks = {}          \n",
    "next_candidate_id = 1\n",
    "csv_buffer = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0202957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_served(lat, lon):\n",
    "    return any(\n",
    "        geodesic((lat, lon), s).meters < SERVE_RADIUS\n",
    "        for s in served_targets\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54180dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(frame, conf=CONF_TH, verbose=False)[0]\n",
    "\n",
    "    for box in results.boxes:\n",
    "        if int(box.cls[0]) != PERSON_CLASS_ID:\n",
    "            continue\n",
    "\n",
    "        # ---- Bounding box from YOLO (THIS IS ALL YOU NEED) ----\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "        gps = get_geotag(\n",
    "            bbox=(x1, y1, x2, y2),\n",
    "            frame = frame,\n",
    "            drone_lat=drone_lat,\n",
    "            drone_lon=drone_lon,\n",
    "            drone_alt=drone_alt,\n",
    "            imu_roll=imu_roll,\n",
    "            imu_pitch=imu_pitch,\n",
    "            imu_yaw=imu_yaw,\n",
    "            gimbal_pitch=gimbal_pitch\n",
    "        )\n",
    "\n",
    "        # gps = get_geotag_precise(\n",
    "        #     bbox=(x1, y1, x2, y2),\n",
    "        #     frame = frame,\n",
    "        #     drone_lat=drone_lat,\n",
    "        #     drone_lon=drone_lon,\n",
    "        #     drone_alt=drone_alt,\n",
    "        #     yaw_deg = imu_yaw,          # heading of drone\n",
    "        #     gimbal_pitch_deg  = gimbal_pitch     # NEGATIVE (e.g. -35)\n",
    "        # )\n",
    "\n",
    "#         gps = get_geotag_precise(\n",
    "#             drone_lat = drone_lat,\n",
    "#             drone_lon = drone_lon,\n",
    "#             drone_alt = drone_alt,        # meters AGL\n",
    "#             yaw_deg = imu_yaw,          # ABSOLUTE yaw (0 = North, CW positive)\n",
    "#             gimbal_pitch_deg = gimbal_pitch, # negative down (e.g. -35)\n",
    "#             bbox = (x1, y1, x2, y2),\n",
    "#             img_w = frame.shape[1],\n",
    "#             img_h = frame.shape[0],\n",
    "#             hfov_deg = 81.4\n",
    "# )\n",
    "\n",
    "        if gps is None:\n",
    "            continue\n",
    "\n",
    "        lat, lon = gps\n",
    "\n",
    "        if is_served(lat, lon):\n",
    "            continue\n",
    "\n",
    "        # ---- TRACK MATCHING ----\n",
    "        matched_id = None\n",
    "        for cid, track in candidate_tracks.items():\n",
    "            if track[\"confirmed\"]:\n",
    "                continue\n",
    "            d = geodesic((lat, lon), (track[\"lat\"], track[\"lon\"])).meters\n",
    "            if d < SAME_PERSON_RADIUS:\n",
    "                matched_id = cid\n",
    "                break\n",
    "\n",
    "        # ---- NEW PERSON ----\n",
    "        if matched_id is None:\n",
    "            candidate_tracks[next_candidate_id] = {\n",
    "                \"lat\": lat,\n",
    "                \"lon\": lon,\n",
    "                \"count\": 1,\n",
    "                \"lat_buf\": deque([lat], maxlen=AVG_WINDOW),\n",
    "                \"lon_buf\": deque([lon], maxlen=AVG_WINDOW),\n",
    "                \"confirmed\": False\n",
    "            }\n",
    "            print(f\"[NEW] Person ID {next_candidate_id}\")\n",
    "            matched_id = next_candidate_id\n",
    "            next_candidate_id += 1\n",
    "\n",
    "        # ---- EXISTING PERSON ----\n",
    "        else:\n",
    "            track = candidate_tracks[matched_id]\n",
    "            track[\"count\"] += 1\n",
    "\n",
    "            track[\"lat\"] = lat\n",
    "            track[\"lon\"] = lon\n",
    "            track[\"lat_buf\"].append(lat)\n",
    "            track[\"lon_buf\"].append(lon)\n",
    "\n",
    "            print(f\"[TRACK] ID {matched_id} count={track['count']}\")\n",
    "\n",
    "            # ---- CONFIRM PERSON ----\n",
    "            if track[\"count\"] >= FRAME_CONFIRM and not track[\"confirmed\"]:\n",
    "                avg_lat = float(np.median(track[\"lat_buf\"]))\n",
    "                avg_lon = float(np.median(track[\"lon_buf\"]))\n",
    "\n",
    "                print(\n",
    "                    f\"üéØ DROP TARGET ID {matched_id}: \"\n",
    "                    f\"{avg_lat:.6f}, {avg_lon:.6f}\"\n",
    "                )\n",
    "\n",
    "                served_targets.append((avg_lat, avg_lon))\n",
    "                track[\"confirmed\"] = True\n",
    "\n",
    "                csv_buffer.append([\n",
    "                    matched_id,\n",
    "                    avg_lat,\n",
    "                    avg_lon,\n",
    "                    time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                ])\n",
    "\n",
    "\n",
    "# ================= SAVE CSV =================\n",
    "with open(\"geotagged_person_locations.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"person_id\", \"latitude\", \"longitude\", \"timestamp\"])\n",
    "    writer.writerows(csv_buffer)\n",
    "\n",
    "cap.release()\n",
    "print(\"üõë SYSTEM STOPPED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69c9fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SAVED HUMAN ID 1 (conf=0.66)\n",
      "‚úÖ SAVED HUMAN ID 2 (conf=0.72)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ===================== PATHS =====================\n",
    "MODEL_PATH = r\"E:\\NIDAR\\runs\\detect\\human_detection_y8n_stage22\\weights\\best.pt\"\n",
    "VIDEO_PATH = r\"F:\\dowloads\\PixVerse_V5.5_Image_Text_360P_I_want_a_video_i.mp4\"\n",
    "\n",
    "SAVE_DIR = \"detections\"\n",
    "IMG_DIR = os.path.join(SAVE_DIR, \"images\")\n",
    "CSV_PATH = os.path.join(SAVE_DIR, \"final_human_coordinates.csv\")\n",
    "\n",
    "os.makedirs(IMG_DIR, exist_ok=True)\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# ===================== CAMERA CALIBRATION =====================\n",
    "CAMERA_MATRIX = np.array([\n",
    "    [1176.58, 0.0, 999.32],\n",
    "    [0.0, 1176.61, 522.03],\n",
    "    [0.0, 0.0, 1.0]\n",
    "], dtype=np.float64)\n",
    "\n",
    "DIST_COEFFS = np.array([\n",
    "    0.25010672,\n",
    "   -0.53448585,\n",
    "   -0.01314542,\n",
    "    0.01928691,\n",
    "    0.4317226\n",
    "], dtype=np.float64)\n",
    "\n",
    "fx = CAMERA_MATRIX[0, 0]\n",
    "fy = CAMERA_MATRIX[1, 1]\n",
    "cx0 = CAMERA_MATRIX[0, 2]\n",
    "cy0 = CAMERA_MATRIX[1, 2]\n",
    "\n",
    "# ===================== PARAMETERS =====================\n",
    "PERSON_CLASS_ID = 0\n",
    "CONF_TH = 0.60        # üî• STRICT CONFIDENCE THRESHOLD\n",
    "\n",
    "BOTTOM_RATIO = 0.5\n",
    "CENTER_LEFT_RATIO = 0.3\n",
    "CENTER_RIGHT_RATIO = 0.7\n",
    "\n",
    "CAM_PITCH = math.radians(35)\n",
    "FRAME_CONFIRM = 7\n",
    "DUPLICATE_RADIUS_M = 1.5\n",
    "CELL_SIZE_M = 1.0\n",
    "\n",
    "# ===================== DRONE STATE =====================\n",
    "DRONE_LAT = 25.2621092\n",
    "DRONE_LON = 82.9840395\n",
    "DRONE_ALT = 15.0\n",
    "\n",
    "# ===================== CSV INIT =====================\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    with open(CSV_PATH, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"timestamp\", \"human_id\", \"latitude\", \"longitude\"])\n",
    "\n",
    "# ===================== HELPERS =====================\n",
    "def haversine_m(lat1, lon1, lat2, lon2):\n",
    "    R = 6378137.0\n",
    "    dlat = math.radians(lat2 - lat1)\n",
    "    dlon = math.radians(lon2 - lon1)\n",
    "    a = (math.sin(dlat / 2) ** 2 +\n",
    "         math.cos(math.radians(lat1)) *\n",
    "         math.cos(math.radians(lat2)) *\n",
    "         math.sin(dlon / 2) ** 2)\n",
    "    return R * 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "# ===================== MODEL & CAMERA =====================\n",
    "model = YOLO(MODEL_PATH)\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "\n",
    "# ===================== MEMORY =====================\n",
    "humans = []                 # [{\"id\": int, \"lat\": float, \"lon\": float}]\n",
    "saved_ids = set()           # IDs already written to CSV\n",
    "candidate_counter = {}      # {(cell_x, cell_y): count}\n",
    "next_human_id = 1\n",
    "\n",
    "# ===================== MAIN LOOP =====================\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.undistort(frame, CAMERA_MATRIX, DIST_COEFFS)\n",
    "    h, w = frame.shape[:2]\n",
    "    bottom_limit = int(BOTTOM_RATIO * h)\n",
    "\n",
    "    results = model(frame, conf=CONF_TH, verbose=False)[0]\n",
    "    seen_cells = set()\n",
    "\n",
    "    if results.boxes is not None:\n",
    "        for box in results.boxes:\n",
    "\n",
    "            # ---------- CLASS FILTER ----------\n",
    "            if int(box.cls[0]) != PERSON_CLASS_ID:\n",
    "                continue\n",
    "\n",
    "            # ---------- CONFIDENCE FILTER (FINAL GUARD) ----------\n",
    "            conf = float(box.conf[0])\n",
    "            if conf < 0.65:\n",
    "                continue\n",
    "\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            u = (x1 + x2) / 2\n",
    "            v = (y1 + y2) / 2\n",
    "\n",
    "            # ---------- BOTTOM-FRAME FILTER ----------\n",
    "            if v < bottom_limit:\n",
    "                continue\n",
    "\n",
    "            # ---------- CLAMP HORIZONTAL OFFSET ----------\n",
    "            cl = CENTER_LEFT_RATIO * w\n",
    "            cr = CENTER_RIGHT_RATIO * w\n",
    "\n",
    "            if cl < u < cr:\n",
    "                u_used = cx0\n",
    "            elif u <= cl:\n",
    "                u_used = cl\n",
    "            else:\n",
    "                u_used = cr\n",
    "\n",
    "            v_used = bottom_limit\n",
    "\n",
    "            # ---------- PIXEL ‚Üí ANGLES ----------\n",
    "            theta_x = math.atan((u_used - cx0) / fx)\n",
    "            theta_y = math.atan((v_used - cy0) / fy)\n",
    "\n",
    "            ground_angle = CAM_PITCH + theta_y\n",
    "            if ground_angle <= 0:\n",
    "                continue\n",
    "\n",
    "            forward_dist = DRONE_ALT / math.tan(ground_angle)\n",
    "            lateral_dist = forward_dist * math.tan(theta_x)\n",
    "\n",
    "            R = 6378137.0\n",
    "            dlat = (forward_dist / R) * (180 / math.pi)\n",
    "            dlon = (lateral_dist / (R * math.cos(math.radians(DRONE_LAT)))) * (180 / math.pi)\n",
    "\n",
    "            human_lat = DRONE_LAT + dlat\n",
    "            human_lon = DRONE_LON + dlon\n",
    "\n",
    "            cell = (\n",
    "                int(forward_dist / CELL_SIZE_M),\n",
    "                int(lateral_dist / CELL_SIZE_M)\n",
    "            )\n",
    "\n",
    "            seen_cells.add(cell)\n",
    "            candidate_counter[cell] = candidate_counter.get(cell, 0) + 1\n",
    "\n",
    "            # ---------- 7-FRAME CONFIRMATION ----------\n",
    "            if candidate_counter[cell] == FRAME_CONFIRM:\n",
    "\n",
    "                assigned_id = None\n",
    "                for hmn in humans:\n",
    "                    if haversine_m(hmn[\"lat\"], hmn[\"lon\"], human_lat, human_lon) < DUPLICATE_RADIUS_M:\n",
    "                        assigned_id = hmn[\"id\"]\n",
    "                        break\n",
    "\n",
    "                if assigned_id is None:\n",
    "                    assigned_id = next_human_id\n",
    "                    humans.append({\n",
    "                        \"id\": assigned_id,\n",
    "                        \"lat\": human_lat,\n",
    "                        \"lon\": human_lon\n",
    "                    })\n",
    "                    next_human_id += 1\n",
    "\n",
    "                # ---------- SAVE ONLY ONCE PER ID ----------\n",
    "                if assigned_id not in saved_ids:\n",
    "                    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "                    img_path = os.path.join(IMG_DIR, f\"human_{assigned_id}_{ts}.jpg\")\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    cv2.imwrite(img_path, frame)\n",
    "\n",
    "                    with open(CSV_PATH, \"a\", newline=\"\") as f:\n",
    "                        writer = csv.writer(f)\n",
    "                        writer.writerow([\n",
    "                            ts,\n",
    "                            assigned_id,\n",
    "                            round(human_lat, 7),\n",
    "                            round(human_lon, 7)\n",
    "                        ])\n",
    "\n",
    "                    saved_ids.add(assigned_id)\n",
    "                    print(f\"‚úÖ SAVED HUMAN ID {assigned_id} (conf={conf:.2f})\")\n",
    "\n",
    "    candidate_counter = {k: v for k, v in candidate_counter.items() if k in seen_cells}\n",
    "\n",
    "    cv2.line(frame, (0, bottom_limit), (w, bottom_limit), (0, 0, 255), 2)\n",
    "    cv2.imshow(\"Human Detection (CONF ‚â• 0.65)\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fe1fb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SAVED HUMAN ID 1 (conf=0.71)\n",
      "‚úÖ SAVED HUMAN ID 2 (conf=0.67)\n",
      "‚úÖ SAVED HUMAN ID 3 (conf=0.60)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ===================== PATHS =====================\n",
    "MODEL_PATH = r\"E:\\NIDAR\\runs\\detect\\human_detection_y8n_stage22\\weights\\best.pt\"\n",
    "VIDEO_PATH =  r\"F:\\dowloads\\PixVerse_V5.5_Image_Text_360P_I_want_a_video_i.mp4\"\n",
    "\n",
    "SAVE_DIR = \"detections\"\n",
    "IMG_DIR = os.path.join(SAVE_DIR, \"images\")\n",
    "CSV_PATH = os.path.join(SAVE_DIR, \"final_human_coordinates.csv\")\n",
    "\n",
    "os.makedirs(IMG_DIR, exist_ok=True)\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# ===================== CAMERA CALIBRATION =====================\n",
    "CAMERA_MATRIX = np.array([\n",
    "    [1176.58, 0.0, 999.32],\n",
    "    [0.0, 1176.61, 522.03],\n",
    "    [0.0, 0.0, 1.0]\n",
    "], dtype=np.float64)\n",
    "\n",
    "DIST_COEFFS = np.array([\n",
    "    0.25010672,\n",
    "   -0.53448585,\n",
    "   -0.01314542,\n",
    "    0.01928691,\n",
    "    0.4317226\n",
    "], dtype=np.float64)\n",
    "\n",
    "fx = CAMERA_MATRIX[0, 0]\n",
    "fy = CAMERA_MATRIX[1, 1]\n",
    "cx0 = CAMERA_MATRIX[0, 2]\n",
    "cy0 = CAMERA_MATRIX[1, 2]\n",
    "\n",
    "# ===================== PARAMETERS =====================\n",
    "PERSON_CLASS_ID = 0\n",
    "CONF_TH = 0.60\n",
    "\n",
    "BOTTOM_RATIO = 0.5\n",
    "CENTER_LEFT_RATIO = 0.3\n",
    "CENTER_RIGHT_RATIO = 0.7\n",
    "\n",
    "CAM_PITCH = math.radians(35)\n",
    "FRAME_CONFIRM = 4\n",
    "CELL_SIZE_M = 1.0\n",
    "\n",
    "# ===================== DRONE STATE =====================\n",
    "DRONE_LAT = 25.2621092\n",
    "DRONE_LON = 82.9840395\n",
    "DRONE_ALT = 15.0\n",
    "\n",
    "# ===================== CSV INIT =====================\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    with open(CSV_PATH, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"timestamp\", \"human_id\", \"latitude\", \"longitude\"])\n",
    "\n",
    "# ===================== MODEL & VIDEO =====================\n",
    "model = YOLO(MODEL_PATH)\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "\n",
    "# ===================== MEMORY =====================\n",
    "saved_ids = set()\n",
    "candidate_counter = {}\n",
    "cell_to_id = {}\n",
    "next_human_id = 1\n",
    "\n",
    "# ===================== MAIN LOOP =====================\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.undistort(frame, CAMERA_MATRIX, DIST_COEFFS)\n",
    "    h, w = frame.shape[:2]\n",
    "    bottom_limit = int(BOTTOM_RATIO * h)\n",
    "\n",
    "    results = model(frame, conf=CONF_TH, verbose=False)[0]\n",
    "    seen_cells = set()\n",
    "\n",
    "    if results.boxes is not None:\n",
    "        for box in results.boxes:\n",
    "\n",
    "            # -------- CLASS --------\n",
    "            if int(box.cls[0]) != PERSON_CLASS_ID:\n",
    "                continue\n",
    "\n",
    "            # -------- CONFIDENCE --------\n",
    "            conf = float(box.conf[0])\n",
    "            if conf < CONF_TH:\n",
    "                continue\n",
    "\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            u = (x1 + x2) / 2\n",
    "            v = (y1 + y2) / 2\n",
    "\n",
    "            # -------- BOTTOM FILTER --------\n",
    "            if v < bottom_limit:\n",
    "                continue\n",
    "\n",
    "            # -------- CLAMP --------\n",
    "            cl = CENTER_LEFT_RATIO * w\n",
    "            cr = CENTER_RIGHT_RATIO * w\n",
    "\n",
    "            if cl < u < cr:\n",
    "                u_used = cx0\n",
    "            elif u <= cl:\n",
    "                u_used = cl\n",
    "            else:\n",
    "                u_used = cr\n",
    "\n",
    "            v_used = bottom_limit\n",
    "\n",
    "            # -------- ANGLES --------\n",
    "            theta_x = math.atan((u_used - cx0) / fx)\n",
    "            theta_y = math.atan((v_used - cy0) / fy)\n",
    "\n",
    "            ground_angle = CAM_PITCH + theta_y\n",
    "            if ground_angle <= 0:\n",
    "                continue\n",
    "\n",
    "            forward_dist = DRONE_ALT / math.tan(ground_angle)\n",
    "            lateral_dist = forward_dist * math.tan(theta_x)\n",
    "\n",
    "            R = 6378137.0\n",
    "            dlat = (forward_dist / R) * (180 / math.pi)\n",
    "            dlon = (lateral_dist / (R * math.cos(math.radians(DRONE_LAT)))) * (180 / math.pi)\n",
    "\n",
    "            human_lat = DRONE_LAT + dlat\n",
    "            human_lon = DRONE_LON + dlon\n",
    "\n",
    "            cell = (\n",
    "                int(forward_dist / CELL_SIZE_M),\n",
    "                int(lateral_dist / CELL_SIZE_M)\n",
    "            )\n",
    "\n",
    "            seen_cells.add(cell)\n",
    "            candidate_counter[cell] = candidate_counter.get(cell, 0) + 1\n",
    "\n",
    "            # -------- CONFIRM AFTER 7 FRAMES --------\n",
    "            if candidate_counter[cell] == FRAME_CONFIRM:\n",
    "\n",
    "                if cell not in cell_to_id:\n",
    "                    cell_to_id[cell] = next_human_id\n",
    "                    next_human_id += 1\n",
    "\n",
    "                assigned_id = cell_to_id[cell]\n",
    "\n",
    "                if assigned_id not in saved_ids:\n",
    "                    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "                    # ‚úÖ DRAW BOUNDING BOX ON IMAGE\n",
    "                    save_img = frame.copy()\n",
    "                    cv2.rectangle(save_img, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "                    cv2.putText(\n",
    "                        save_img,\n",
    "                        f\"ID {assigned_id}\",\n",
    "                        (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.7,\n",
    "                        (0, 255, 0),\n",
    "                        2\n",
    "                    )\n",
    "\n",
    "                    img_path = os.path.join(\n",
    "                        IMG_DIR, f\"human_{assigned_id}_{ts}.jpg\"\n",
    "                    )\n",
    "                    cv2.imwrite(img_path, save_img)\n",
    "\n",
    "                    with open(CSV_PATH, \"a\", newline=\"\") as f:\n",
    "                        writer = csv.writer(f)\n",
    "                        writer.writerow([\n",
    "                            ts,\n",
    "                            assigned_id,\n",
    "                            round(human_lat, 7),\n",
    "                            round(human_lon, 7)\n",
    "                        ])\n",
    "\n",
    "                    saved_ids.add(assigned_id)\n",
    "                    print(f\"‚úÖ SAVED HUMAN ID {assigned_id} (conf={conf:.2f})\")\n",
    "\n",
    "    # cleanup\n",
    "    candidate_counter = {\n",
    "        k: v for k, v in candidate_counter.items() if k in seen_cells\n",
    "    }\n",
    "\n",
    "    cv2.line(frame, (0, bottom_limit), (w, bottom_limit), (0, 0, 255), 2)\n",
    "    cv2.imshow(\"Human Detection (BBox Saved)\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46e3ec8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SAVED human ID 1 (conf=0.73)\n",
      "‚úÖ SAVED human ID 2 (conf=0.65)\n",
      "‚úÖ SAVED human ID 6 (conf=0.76)\n",
      "‚úÖ SAVED human ID 7 (conf=0.72)\n",
      "‚úÖ SAVED human ID 9 (conf=0.69)\n",
      "‚úÖ SAVED human ID 14 (conf=0.65)\n",
      "‚úÖ SAVED human ID 15 (conf=0.79)\n",
      "‚úÖ SAVED human ID 18 (conf=0.66)\n",
      "‚úÖ SAVED human ID 21 (conf=0.69)\n",
      "‚úÖ SAVED human ID 27 (conf=0.65)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ===================== PATHS =====================\n",
    "MODEL_PATH = r\"E:\\NIDAR\\runs\\detect\\human_detection_y8n_stage22\\weights\\best.pt\"\n",
    "VIDEO_PATH = r\"F:\\New folder\\video_20260111_144158 - Trim - Trim.mp4\"\n",
    "\n",
    "SAVE_DIR = \"detected_humans\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# ===================== PARAMETERS =====================\n",
    "PERSON_CLASS_ID = 0\n",
    "CONF_TH = 0.65   # confidence threshold\n",
    "\n",
    "# ===================== MODEL & VIDEO =====================\n",
    "model = YOLO(MODEL_PATH)\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "\n",
    "# ===================== MEMORY =====================\n",
    "saved_track_ids = set()   # save each person only once\n",
    "\n",
    "# ===================== MAIN LOOP =====================\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run YOLO with tracking\n",
    "    results = model.track(\n",
    "        frame,\n",
    "        conf=CONF_TH,\n",
    "        persist=True,\n",
    "        verbose=False\n",
    "    )[0]\n",
    "\n",
    "    if results.boxes is None:\n",
    "        cv2.imshow(\"Human Detection\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "        continue\n",
    "\n",
    "    for box in results.boxes:\n",
    "\n",
    "        # -------- CLASS FILTER --------\n",
    "        if int(box.cls[0]) != PERSON_CLASS_ID:\n",
    "            continue\n",
    "\n",
    "        # -------- TRACK ID CHECK --------\n",
    "        if box.id is None:\n",
    "            continue\n",
    "\n",
    "        track_id = int(box.id[0])\n",
    "\n",
    "        # Already saved ‚Üí skip\n",
    "        if track_id in saved_track_ids:\n",
    "            continue\n",
    "\n",
    "        # -------- CONFIDENCE FILTER --------\n",
    "        conf = float(box.conf[0])\n",
    "        if conf < CONF_TH:\n",
    "            continue\n",
    "\n",
    "        # -------- DRAW BOUNDING BOX --------\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        save_frame = frame.copy()\n",
    "\n",
    "        cv2.rectangle(save_frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "        cv2.putText(\n",
    "            save_frame,\n",
    "            f\"Human ID {track_id}\",\n",
    "            (x1, y1 - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.7,\n",
    "            (0, 255, 0),\n",
    "            2\n",
    "        )\n",
    "\n",
    "        # -------- SAVE FRAME --------\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        img_path = os.path.join(\n",
    "            SAVE_DIR, f\"human_{track_id}_{timestamp}.jpg\"\n",
    "        )\n",
    "\n",
    "        cv2.imwrite(img_path, save_frame)\n",
    "        saved_track_ids.add(track_id)\n",
    "\n",
    "        print(f\"‚úÖ SAVED human ID {track_id} (conf={conf:.2f})\")\n",
    "\n",
    "    cv2.imshow(\"Human Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baf29754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Human detection started (terminal-only mode)...\n",
      "‚úÖ SAVED | ID=1 | conf=0.73 | file=detected_humans\\human_1_20260115_143008.jpg\n",
      "‚úÖ SAVED | ID=2 | conf=0.65 | file=detected_humans\\human_2_20260115_143008.jpg\n",
      "‚úÖ SAVED | ID=6 | conf=0.76 | file=detected_humans\\human_6_20260115_143009.jpg\n",
      "‚úÖ SAVED | ID=7 | conf=0.72 | file=detected_humans\\human_7_20260115_143010.jpg\n",
      "‚úÖ SAVED | ID=9 | conf=0.69 | file=detected_humans\\human_9_20260115_143010.jpg\n",
      "‚úÖ SAVED | ID=14 | conf=0.65 | file=detected_humans\\human_14_20260115_143010.jpg\n",
      "‚úÖ SAVED | ID=15 | conf=0.79 | file=detected_humans\\human_15_20260115_143010.jpg\n",
      "‚úÖ SAVED | ID=18 | conf=0.66 | file=detected_humans\\human_18_20260115_143011.jpg\n",
      "‚úÖ SAVED | ID=21 | conf=0.69 | file=detected_humans\\human_21_20260115_143011.jpg\n",
      "‚úÖ SAVED | ID=27 | conf=0.65 | file=detected_humans\\human_27_20260115_143012.jpg\n",
      "‚úÖ SAVED | ID=30 | conf=0.69 | file=detected_humans\\human_30_20260115_143013.jpg\n",
      "‚úÖ SAVED | ID=31 | conf=0.66 | file=detected_humans\\human_31_20260115_143013.jpg\n",
      "‚úÖ SAVED | ID=34 | conf=0.71 | file=detected_humans\\human_34_20260115_143014.jpg\n",
      "üìπ Video ended or camera stopped.\n",
      "üõë Detection stopped.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ===================== PATHS =====================\n",
    "MODEL_PATH = r\"E:\\NIDAR\\runs\\detect\\human_detection_y8n_stage22\\weights\\best.pt\"\n",
    "VIDEO_PATH = r\"F:\\New folder\\video_20260111_144158 - Trim - Trim.mp4\"\n",
    "\n",
    "SAVE_DIR = \"detected_humans\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# ===================== PARAMETERS =====================\n",
    "PERSON_CLASS_ID = 0\n",
    "CONF_TH = 0.65   # confidence threshold\n",
    "\n",
    "# ===================== MODEL & VIDEO =====================\n",
    "model = YOLO(MODEL_PATH)\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "\n",
    "# ===================== MEMORY =====================\n",
    "saved_track_ids = set()   # save each person only once\n",
    "\n",
    "print(\"üöÄ Human detection started (terminal-only mode)...\")\n",
    "\n",
    "# ===================== MAIN LOOP =====================\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"üìπ Video ended or camera stopped.\")\n",
    "        break\n",
    "\n",
    "    # YOLO with tracking\n",
    "    results = model.track(\n",
    "        frame,\n",
    "        conf=CONF_TH,\n",
    "        persist=True,\n",
    "        verbose=False\n",
    "    )[0]\n",
    "\n",
    "    if results.boxes is None:\n",
    "        continue\n",
    "\n",
    "    for box in results.boxes:\n",
    "\n",
    "        # -------- CLASS FILTER --------\n",
    "        if int(box.cls[0]) != PERSON_CLASS_ID:\n",
    "            continue\n",
    "\n",
    "        # -------- TRACK ID CHECK --------\n",
    "        if box.id is None:\n",
    "            continue\n",
    "\n",
    "        track_id = int(box.id[0])\n",
    "\n",
    "        # Already saved ‚Üí skip\n",
    "        if track_id in saved_track_ids:\n",
    "            continue\n",
    "\n",
    "        # -------- CONFIDENCE FILTER --------\n",
    "        conf = float(box.conf[0])\n",
    "        if conf < CONF_TH:\n",
    "            continue\n",
    "\n",
    "        # -------- DRAW BOUNDING BOX --------\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        save_frame = frame.copy()\n",
    "\n",
    "        cv2.rectangle(save_frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "        cv2.putText(\n",
    "            save_frame,\n",
    "            f\"Human ID {track_id} | conf={conf:.2f}\",\n",
    "            (x1, y1 - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.6,\n",
    "            (0, 255, 0),\n",
    "            2\n",
    "        )\n",
    "\n",
    "        # -------- SAVE FRAME --------\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        img_path = os.path.join(\n",
    "            SAVE_DIR, f\"human_{track_id}_{timestamp}.jpg\"\n",
    "        )\n",
    "\n",
    "        cv2.imwrite(img_path, save_frame)\n",
    "        saved_track_ids.add(track_id)\n",
    "\n",
    "        print(f\"‚úÖ SAVED | ID={track_id} | conf={conf:.2f} | file={img_path}\")\n",
    "\n",
    "cap.release()\n",
    "print(\"üõë Detection stopped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba2c3dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Human detection started (GPS logging, no image path)...\n",
      "‚úÖ SAVED | ID=1 | conf=0.73 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=2 | conf=0.65 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=6 | conf=0.76 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=7 | conf=0.72 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=9 | conf=0.69 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=14 | conf=0.65 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=15 | conf=0.79 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=18 | conf=0.66 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=21 | conf=0.69 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=27 | conf=0.65 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=30 | conf=0.69 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=31 | conf=0.66 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=34 | conf=0.71 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "üìπ Video ended or camera stopped.\n",
      "üõë Detection stopped.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ===================== PATHS =====================\n",
    "MODEL_PATH = r\"E:\\NIDAR\\runs\\detect\\human_detection_y8n_stage22\\weights\\best.pt\"\n",
    "VIDEO_PATH = r\"F:\\New folder\\video_20260111_144158 - Trim - Trim.mp4\"\n",
    "\n",
    "SAVE_DIR = \"detected_humans\"\n",
    "IMG_DIR = os.path.join(SAVE_DIR, \"images\")\n",
    "CSV_PATH = os.path.join(SAVE_DIR, \"detections.csv\")\n",
    "\n",
    "os.makedirs(IMG_DIR, exist_ok=True)\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# ===================== PARAMETERS =====================\n",
    "PERSON_CLASS_ID = 0\n",
    "CONF_TH = 0.65\n",
    "\n",
    "# ===================== DRONE GPS (REPLACE WITH MAVLINK) =====================\n",
    "DRONE_LAT = 25.2621092\n",
    "DRONE_LON = 82.9840395\n",
    "DRONE_ALT = 15.0  # meters\n",
    "\n",
    "# ===================== CSV INIT =====================\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    with open(CSV_PATH, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            \"timestamp\",\n",
    "            \"human_id\",\n",
    "            \"confidence\",\n",
    "            \"drone_lat\",\n",
    "            \"drone_lon\",\n",
    "            \"drone_alt\"\n",
    "        ])\n",
    "\n",
    "# ===================== MODEL & VIDEO =====================\n",
    "model = YOLO(MODEL_PATH)\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "\n",
    "# ===================== MEMORY =====================\n",
    "saved_track_ids = set()\n",
    "\n",
    "print(\"üöÄ Human detection started (GPS logging, no image path)...\")\n",
    "\n",
    "# ===================== MAIN LOOP =====================\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"üìπ Video ended or camera stopped.\")\n",
    "        break\n",
    "\n",
    "    results = model.track(\n",
    "        frame,\n",
    "        conf=CONF_TH,\n",
    "        persist=True,\n",
    "        verbose=False\n",
    "    )[0]\n",
    "\n",
    "    if results.boxes is None:\n",
    "        continue\n",
    "\n",
    "    for box in results.boxes:\n",
    "\n",
    "        # -------- CLASS FILTER --------\n",
    "        if int(box.cls[0]) != PERSON_CLASS_ID:\n",
    "            continue\n",
    "\n",
    "        # -------- TRACK ID --------\n",
    "        if box.id is None:\n",
    "            continue\n",
    "\n",
    "        track_id = int(box.id[0])\n",
    "\n",
    "        # Already saved ‚Üí skip\n",
    "        if track_id in saved_track_ids:\n",
    "            continue\n",
    "\n",
    "        # -------- CONFIDENCE FILTER --------\n",
    "        conf = float(box.conf[0])\n",
    "        if conf < CONF_TH:\n",
    "            continue\n",
    "\n",
    "        # -------- DRAW BBOX + GPS --------\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        save_frame = frame.copy()\n",
    "\n",
    "        cv2.rectangle(save_frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "\n",
    "        overlay_lines = [\n",
    "            f\"Human ID: {track_id}\",\n",
    "            f\"Conf: {conf:.2f}\",\n",
    "            f\"Lat: {DRONE_LAT:.6f}\",\n",
    "            f\"Lon: {DRONE_LON:.6f}\",\n",
    "            f\"Alt: {DRONE_ALT:.1f} m\"\n",
    "        ]\n",
    "\n",
    "        y_text = y1 - 10\n",
    "        for line in overlay_lines:\n",
    "            cv2.putText(\n",
    "                save_frame,\n",
    "                line,\n",
    "                (x1, y_text),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.55,\n",
    "                (0, 255, 0),\n",
    "                2\n",
    "            )\n",
    "            y_text -= 20\n",
    "\n",
    "        # -------- SAVE IMAGE --------\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        img_path = os.path.join(\n",
    "            IMG_DIR, f\"human_{track_id}_{timestamp}.jpg\"\n",
    "        )\n",
    "        cv2.imwrite(img_path, save_frame)\n",
    "\n",
    "        # -------- SAVE CSV (NO IMAGE PATH) --------\n",
    "        with open(CSV_PATH, \"a\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                timestamp,\n",
    "                track_id,\n",
    "                round(conf, 3),\n",
    "                round(DRONE_LAT, 7),\n",
    "                round(DRONE_LON, 7),\n",
    "                DRONE_ALT\n",
    "            ])\n",
    "\n",
    "        saved_track_ids.add(track_id)\n",
    "\n",
    "        print(\n",
    "            f\"‚úÖ SAVED | ID={track_id} | conf={conf:.2f} | \"\n",
    "            f\"GPS=({DRONE_LAT:.6f}, {DRONE_LON:.6f}, {DRONE_ALT}m)\"\n",
    "        )\n",
    "\n",
    "cap.release()\n",
    "print(\"üõë Detection stopped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaeafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ===================== PATHS =====================\n",
    "MODEL_PATH = r\"E:\\NIDAR\\runs\\detect\\human_detection_y8n_stage22\\weights\\best.pt\"\n",
    "VIDEO_PATH = r\"F:\\dowloads\\PixVerse_V5.5_Image_Text_360P_I_want_a_video_i (1).mp4\"\n",
    "\n",
    "SAVE_DIR = \"detected_humans\"\n",
    "IMG_DIR = os.path.join(SAVE_DIR, \"images\")\n",
    "CSV_PATH = os.path.join(SAVE_DIR, \"detections.csv\")\n",
    "\n",
    "os.makedirs(IMG_DIR, exist_ok=True)\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# ===================== PARAMETERS =====================\n",
    "PERSON_CLASS_ID = 0\n",
    "CONF_TH = 0.65\n",
    "\n",
    "# ===================== DRONE GPS (REPLACE WITH MAVLINK) =====================\n",
    "DRONE_LAT = 25.2621092\n",
    "DRONE_LON = 82.9840395\n",
    "DRONE_ALT = 15.0  # meters\n",
    "\n",
    "# ===================== CSV INIT =====================\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    with open(CSV_PATH, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            \"timestamp\",\n",
    "            \"human_id\",\n",
    "            \"confidence\",\n",
    "            \"drone_lat\",\n",
    "            \"drone_lon\",\n",
    "            \"drone_alt\"\n",
    "        ])\n",
    "\n",
    "# ===================== MODEL & VIDEO =====================\n",
    "model = YOLO(MODEL_PATH)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# ===================== MEMORY =====================\n",
    "saved_track_ids = set()\n",
    "active_person_id = None   # currently handled person\n",
    "\n",
    "print(\"üöÄ Human detection started (event-based mode)...\")\n",
    "\n",
    "# ===================== MAIN LOOP =====================\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"üìπ Video ended.\")\n",
    "        break\n",
    "\n",
    "    results = model.track(\n",
    "        frame,\n",
    "        conf=CONF_TH,\n",
    "        persist=True,\n",
    "        verbose=False\n",
    "    )[0]\n",
    "\n",
    "    if results.boxes is None:\n",
    "        continue\n",
    "\n",
    "    for box in results.boxes:\n",
    "\n",
    "        # -------- CLASS FILTER --------\n",
    "        if int(box.cls[0]) != PERSON_CLASS_ID:\n",
    "            continue\n",
    "\n",
    "        if box.id is None:\n",
    "            continue\n",
    "\n",
    "        track_id = int(box.id[0])\n",
    "        conf = float(box.conf[0])\n",
    "\n",
    "        # Ignore already saved persons forever\n",
    "        if track_id in saved_track_ids:\n",
    "            continue\n",
    "\n",
    "        # If already processing another person ‚Üí WAIT\n",
    "        if active_person_id is not None and track_id != active_person_id:\n",
    "            continue\n",
    "\n",
    "        if conf < CONF_TH:\n",
    "            continue\n",
    "\n",
    "        # -------- NEW PERSON DETECTED --------\n",
    "        active_person_id = track_id\n",
    "\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        save_frame = frame.copy()\n",
    "\n",
    "        cv2.rectangle(save_frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "\n",
    "        overlay = [\n",
    "            f\"Human ID: {track_id}\",\n",
    "            f\"Conf: {conf:.2f}\",\n",
    "            f\"Lat: {DRONE_LAT:.6f}\",\n",
    "            f\"Lon: {DRONE_LON:.6f}\",\n",
    "            f\"Alt: {DRONE_ALT:.1f} m\"\n",
    "        ]\n",
    "\n",
    "        y = y1 - 10\n",
    "        for line in overlay:\n",
    "            cv2.putText(\n",
    "                save_frame,\n",
    "                line,\n",
    "                (x1, y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.55,\n",
    "                (0, 255, 0),\n",
    "                2\n",
    "            )\n",
    "            y -= 20\n",
    "\n",
    "        # -------- SAVE IMAGE --------\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        img_path = os.path.join(\n",
    "            IMG_DIR, f\"human_{track_id}_{timestamp}.jpg\"\n",
    "        )\n",
    "        cv2.imwrite(img_path, save_frame)\n",
    "\n",
    "        # -------- SAVE CSV --------\n",
    "        with open(CSV_PATH, \"a\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                timestamp,\n",
    "                track_id,\n",
    "                round(conf, 3),\n",
    "                round(DRONE_LAT, 7),\n",
    "                round(DRONE_LON, 7),\n",
    "                DRONE_ALT\n",
    "            ])\n",
    "\n",
    "        saved_track_ids.add(track_id)\n",
    "        active_person_id = None  # RESET ‚Üí wait for new person\n",
    "\n",
    "        print(\n",
    "            f\"‚úÖ SAVED | ID={track_id} | conf={conf:.2f} | \"\n",
    "            f\"GPS=({DRONE_LAT:.6f}, {DRONE_LON:.6f}, {DRONE_ALT}m)\"\n",
    "        )\n",
    "\n",
    "        break  # stop checking other boxes this frame\n",
    "\n",
    "cap.release()\n",
    "print(\"üõë Detection stopped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6e67840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Human detection started (with live output)...\n",
      "‚úÖ SAVED | ID=1 | conf=0.77 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=4 | conf=0.70 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=5 | conf=0.68 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=6 | conf=0.66 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=7 | conf=0.67 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=9 | conf=0.65 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=10 | conf=0.69 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=2 | conf=0.74 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=15 | conf=0.69 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=18 | conf=0.73 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=20 | conf=0.66 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=21 | conf=0.67 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=23 | conf=0.69 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=24 | conf=0.66 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=27 | conf=0.69 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=28 | conf=0.70 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=29 | conf=0.67 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "‚úÖ SAVED | ID=30 | conf=0.70 | GPS=(25.262109, 82.984039, 15.0m)\n",
      "üìπ Video ended.\n",
      "üõë Detection stopped.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ===================== PATHS =====================\n",
    "MODEL_PATH = r\"E:\\NIDAR\\runs\\detect\\human_detection_y8n_stage22\\weights\\best.pt\"\n",
    "VIDEO_PATH = r\"F:\\dowloads\\PixVerse_V5.5_Image_Text_360P_I_want_a_video_i.mp4\"\n",
    "\n",
    "SAVE_DIR = \"detected_humans\"\n",
    "IMG_DIR = os.path.join(SAVE_DIR, \"images\")\n",
    "CSV_PATH = os.path.join(SAVE_DIR, \"detections.csv\")\n",
    "\n",
    "os.makedirs(IMG_DIR, exist_ok=True)\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# ===================== PARAMETERS =====================\n",
    "PERSON_CLASS_ID = 0\n",
    "CONF_TH = 0.65\n",
    "\n",
    "# ===================== DRONE GPS (REPLACE WITH MAVLINK) =====================\n",
    "DRONE_LAT = 25.2621092\n",
    "DRONE_LON = 82.9840395\n",
    "DRONE_ALT = 15.0  # meters\n",
    "\n",
    "# ===================== CSV INIT =====================\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    with open(CSV_PATH, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            \"timestamp\",\n",
    "            \"human_id\",\n",
    "            \"confidence\",\n",
    "            \"drone_lat\",\n",
    "            \"drone_lon\",\n",
    "            \"drone_alt\"\n",
    "        ])\n",
    "\n",
    "# ===================== MODEL & VIDEO =====================\n",
    "model = YOLO(MODEL_PATH)\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "\n",
    "# ===================== MEMORY =====================\n",
    "saved_track_ids = set()\n",
    "active_person_id = None\n",
    "\n",
    "print(\"üöÄ Human detection started (with live output)...\")\n",
    "\n",
    "# ===================== MAIN LOOP =====================\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"üìπ Video ended.\")\n",
    "        break\n",
    "\n",
    "    frame_to_show = frame.copy()\n",
    "\n",
    "    results = model.track(\n",
    "        frame,\n",
    "        conf=CONF_TH,\n",
    "        persist=True,\n",
    "        verbose=False\n",
    "    )[0]\n",
    "\n",
    "    if results.boxes is not None:\n",
    "\n",
    "        for box in results.boxes:\n",
    "\n",
    "            # -------- CLASS FILTER --------\n",
    "            if int(box.cls[0]) != PERSON_CLASS_ID:\n",
    "                continue\n",
    "\n",
    "            if box.id is None:\n",
    "                continue\n",
    "\n",
    "            track_id = int(box.id[0])\n",
    "            conf = float(box.conf[0])\n",
    "\n",
    "            # Ignore already saved persons\n",
    "            if track_id in saved_track_ids:\n",
    "                continue\n",
    "\n",
    "            # Wait until current person is saved\n",
    "            if active_person_id is not None and track_id != active_person_id:\n",
    "                continue\n",
    "\n",
    "            if conf < CONF_TH:\n",
    "                continue\n",
    "\n",
    "            active_person_id = track_id\n",
    "\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "            # -------- DRAW BBOX --------\n",
    "            cv2.rectangle(frame_to_show, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "\n",
    "            overlay = [\n",
    "                f\"Human ID: {track_id}\",\n",
    "                f\"Conf: {conf:.2f}\",\n",
    "                f\"Lat: {DRONE_LAT:.6f}\",\n",
    "                f\"Lon: {DRONE_LON:.6f}\",\n",
    "                f\"Alt: {DRONE_ALT:.1f} m\"\n",
    "            ]\n",
    "\n",
    "            y = y1 - 10\n",
    "            for line in overlay:\n",
    "                cv2.putText(\n",
    "                    frame_to_show,\n",
    "                    line,\n",
    "                    (x1, y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.55,\n",
    "                    (0, 255, 0),\n",
    "                    2\n",
    "                )\n",
    "                y -= 20\n",
    "\n",
    "            # -------- SAVE IMAGE --------\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            img_path = os.path.join(\n",
    "                IMG_DIR, f\"human_{track_id}_{timestamp}.jpg\"\n",
    "            )\n",
    "            cv2.imwrite(img_path, frame_to_show)\n",
    "\n",
    "            # -------- SAVE CSV --------\n",
    "            with open(CSV_PATH, \"a\", newline=\"\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([\n",
    "                    timestamp,\n",
    "                    track_id,\n",
    "                    round(conf, 3),\n",
    "                    round(DRONE_LAT, 7),\n",
    "                    round(DRONE_LON, 7),\n",
    "                    DRONE_ALT\n",
    "                ])\n",
    "\n",
    "            saved_track_ids.add(track_id)\n",
    "            active_person_id = None\n",
    "\n",
    "            print(\n",
    "                f\"‚úÖ SAVED | ID={track_id} | conf={conf:.2f} | \"\n",
    "                f\"GPS=({DRONE_LAT:.6f}, {DRONE_LON:.6f}, {DRONE_ALT}m)\"\n",
    "            )\n",
    "\n",
    "            break  # process only one person per frame\n",
    "\n",
    "    # ===================== SHOW OUTPUT =====================\n",
    "    cv2.imshow(\"Human Detection\", frame_to_show)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"üõë User stopped.\")\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"üõë Detection stopped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4256c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Ultralytics)",
   "language": "python",
   "name": "ultra-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
