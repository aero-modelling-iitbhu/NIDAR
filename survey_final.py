"""
Docstring for res_2

Command: python3 res_2.py --kml demo_survey_area_new.kml --speed 5.0

Camera connection: Line

Pixhawk connection Line: 198, 1017 ('/dev/ttyACM0')

Alt: 201
Swath lenght: 202
Speed: 203

SAME_PERSON_RADIUS: 336
SERVE_RADIUS: 337

Sim to raspi:

Line: 209, 254, 1032

"""



import argparse
import xml.etree.ElementTree as ET
import logging
import random
from pymavlink import mavutil
import time
import threading
import math
import sys
import os
import numpy as np
import cv2
import csv
import subprocess
from geopy.distance import geodesic
from collections import deque
from ultralytics import YOLO
import termios
import tty
import select

# ===================== CAMERA CALIBRATION =====================
CAMERA_MATRIX = np.array([
    [1176.58, 0.0, 999.32],
    [0.0, 1176.61, 522.03],
    [0.0, 0.0, 1.0]
], dtype=np.float64)

DIST_COEFFS = np.array([
    0.25010672,
   -0.53448585,
   -0.01314542,
    0.01928691,
    0.4317226
], dtype=np.float64)

fx = CAMERA_MATRIX[0, 0]
fy = CAMERA_MATRIX[1, 1]
cx0 = CAMERA_MATRIX[0, 2]
cy0 = CAMERA_MATRIX[1, 2]

# ===================== PARAMETERS =====================
PERSON_CLASS_ID = 0
CONF_TH = 0.60         # ðŸ”¥ STRICT CONFIDENCE THRESHOLD

BOTTOM_RATIO = 0.5
CENTER_LEFT_RATIO = 0.3
CENTER_RIGHT_RATIO = 0.7

CAM_PITCH = math.radians(35)
FRAME_CONFIRM = 7
DUPLICATE_RADIUS_M = 5
CELL_SIZE_M = 1.0


class ThreadedVideoCapture:
    """
    Spawns a dark thread that continually reads the latest frame
    from the video stream and discards the old ones.
    """
    def __init__(self, src):
        self.cap = cv2.VideoCapture(src)
        self.ret, self.frame = self.cap.read()
        self.stopped = False
        self.lock = threading.Lock()
        
        # Start the background thread
        if self.cap.isOpened():
            self.thread = threading.Thread(target=self.update, args=())
            self.thread.daemon = True
            self.thread.start()

    def update(self):
        while not self.stopped:
            ret, frame = self.cap.read()
            if not ret:
                self.stopped = True
                break
            
            with self.lock:
                self.ret = ret
                self.frame = frame
            time.sleep(0.005) # slight yield

    def read(self):
        with self.lock:
            return self.ret, self.frame.copy() if self.frame is not None else None

    def isOpened(self):
        return self.cap.isOpened()

    def release(self):
        self.stopped = True
        if hasattr(self, 'thread'):
            self.thread.join(timeout=1.0)
        self.cap.release()


class GridSurveyNode:

    def __init__(self, connection_string='/dev/ttyACM0'):
        
    # def __init__(self, connection_string='udp:127.0.0.1:14551'):
        # super().__init__('grid_survey_node') 
        logging.info('Grid Survey Node Started')

        # mission parameters
        self.altitude = 15.0               # meters
        self.spacing = 0.00010             # degrees approx (lat)
        self.speed = 3.0                   # m/s
        self.kml_file = None
        self.polygon_coords = []           # list of (lat, lon)

        # Geotagging / Detection State
        self.latest_frame = None
        self.imu_roll = 0.0
        self.imu_pitch = 0.0
        self.imu_yaw = 0.0
        self.gimbal_pitch = -35.0 # Fixed or read from MOUNT_STATUS
        
        # MAVLink State Cache
        self.current_lat = None
        self.current_lon = None
        self.current_alt = None # relative
        self.current_hdg = 0.0  # True North Heading (deg)
        self.connected = False
        self.mutex = threading.Lock()
        
        # Detection Control
        self.detection_active = False
        self.rtsp_url = 0
        self.mqtt_started = False
        
        # Batching State
        self.batch_id = 1
        self.ids_in_current_batch = 0
        
        self.SAVE_DIR = "detections"
        self.IMG_DIR = os.path.join(self.SAVE_DIR, "images")
        self.CSV_PATH = os.path.join(self.SAVE_DIR, "final_human_coordinates.csv")

        os.makedirs(self.IMG_DIR, exist_ok=True)
        os.makedirs(self.SAVE_DIR, exist_ok=True)

        # ===================== CSV INIT =====================
        if not os.path.exists(self.CSV_PATH):
            with open(self.CSV_PATH, "w", newline="") as f:
                writer = csv.writer(f)
                writer.writerow(["timestamp", "human_id", "latitude", "longitude"])
        
        # ===================== MEMORY =====================
        self.humans = []                 # [{"id": int, "lat": float, "lon": float}]
        self.saved_ids = set()           # IDs already written to CSV
        self.candidate_counter = {}      # {(cell_x, cell_y): count}
        self.next_human_id = 1

        # acceptance criteria
        self.accept_radius_m = 20.0         # meters to consider waypoint reached
        self.waypoint_timeout_s = 400       # seconds to wait for a waypoint

        # control flags
        self.stop_requested = False
        self.mission_thread = None
        self.served_targets = [] # Initialize list of served targets

        # connect to vehicle
        self.master = mavutil.mavlink_connection(connection_string, baud=115200, autoreconnect=True)
        # self.master = mavutil.mavlink_connection(connection_string)
        self.master.wait_heartbeat()
        self.connected = True
        logging.info("Connected to vehicle via MAVLink")

        # Start MAVLink Listener Thread
        self.listener_thread = threading.Thread(target=self._mavlink_listener, daemon=True)
        self.listener_thread.start()



        # start mission in background thread
        self.mission_thread = threading.Thread(target=self.load_and_run_mission, daemon=True)
        
        # Detection thread (started later)
        self.detect_thread = threading.Thread(target=self.detection_loop, daemon=True)

        # Keyboard listener thread
        self.keyboard_thread = threading.Thread(target=self.monitor_keyboard, daemon=True)
        self.keyboard_thread.start()

    def _mavlink_listener(self):
        """
        Continuously reads MAVLink messages and updates state variables.
        This prevents race conditions on recv_match and ensures fresh data (especially ATTITUDE) is available.
        """
        while not self.stop_requested:
            try:
                # Read any message
                msg = self.master.recv_match(blocking=True, timeout=1.0)
                if not msg:
                    continue

                type_ = msg.get_type()

                if type_ == 'GLOBAL_POSITION_INT':
                    with self.mutex:
                        self.current_lat = msg.lat / 1e7
                        self.current_lon = msg.lon / 1e7
                        self.current_alt = msg.relative_alt / 1000.0
                        self.current_hdg = msg.hdg / 100.0 # cdeg to deg

                elif type_ == 'ATTITUDE':
                    with self.mutex:
                        self.imu_roll = math.degrees(msg.roll)
                        self.imu_pitch = math.degrees(msg.pitch)
                        self.imu_yaw = math.degrees(msg.yaw) # 0..360 usually

                elif type_ == 'HEARTBEAT':
                    # Could update mode here if needed
                    pass
                
                # Add MOUNT_STATUS handling here if using gimbal feedback

            except Exception as e:
                logging.debug(f"Listener error: {e}")
                time.sleep(0.1)

    def start_mission(self):
        self.mission_thread.start()

    def start_detection(self):
        if not self.detection_active:
            self.detection_active = True
            self.detect_thread.start()
            logging.info("Detection thread started.")

    def detection_loop(self):
        """
        Runs YOLO detection on video stream.
        """
        # Load Model
        logging.info("Loading YOLO model...")
        try:
            model = YOLO("best.pt") # Ensure path is correct or absolute
        except Exception as e:
            logging.error(f"Failed to load YOLO model: {e}")
            return

        # Connect to Stream
        logging.info(f"Connecting to video stream: {self.rtsp_url}")
        cap = ThreadedVideoCapture(self.rtsp_url)
        time.sleep(2.0) # Warmup

        logging.info("Detection loop running...")

        while not self.stop_requested:
            if not cap.isOpened():
                time.sleep(1.0)
                continue

            ret, frame = cap.read()
            if not ret or frame is None:
                time.sleep(0.01)
                continue

            frame = cv2.undistort(frame, CAMERA_MATRIX, DIST_COEFFS)
            h, w = frame.shape[:2]
            bottom_limit = int(BOTTOM_RATIO * h)

            results = model(frame, conf=CONF_TH, verbose=False)[0]
            seen_cells = set()

            # Get current state snapshot (Thread-safe read)
            with self.mutex:
                curr_lat = self.current_lat
                curr_lon = self.current_lon
                curr_alt = self.current_alt
            
            if curr_lat is None or curr_alt is None:
                continue

            if results.boxes is not None:
                for box in results.boxes:
                    # ---------- CLASS FILTER ----------
                    if int(box.cls[0]) != PERSON_CLASS_ID:
                        continue

                    # ---------- CONFIDENCE FILTER (FINAL GUARD) ----------
                    conf = float(box.conf[0])
                    if conf < CONF_TH:
                        continue

                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    u = (x1 + x2) / 2
                    v = (y1 + y2) / 2

                    # ---------- BOTTOM-FRAME FILTER ----------
                    if v < bottom_limit:
                        continue

                    # ---------- CLAMP HORIZONTAL OFFSET ----------
                    cl = CENTER_LEFT_RATIO * w
                    cr = CENTER_RIGHT_RATIO * w

                    if cl < u < cr:
                        u_used = cx0
                    elif u <= cl:
                        u_used = cl
                    else:
                        u_used = cr

                    v_used = bottom_limit

                    # ---------- PIXEL â†’ ANGLES ----------
                    theta_x = math.atan((u_used - cx0) / fx)
                    theta_y = math.atan((v_used - cy0) / fy)

                    # For ground_angle, we need camera pitch.
                    # survey_final.py uses fixed CAM_PITCH.
                    # survey.py has self.imu_pitch and self.gimbal_pitch.
                    # User requested COPY of strategy. survey_final uses constant CAM_PITCH.
                    # However, preserving valid drone dynamic pitch might be better?
                    # But the user said "Copy the detection strategy". 
                    # survey_final.py has `CAM_PITCH = math.radians(35)`.
                    # I will use CAM_PITCH from constants as requested to match logic exactly.
                    
                    ground_angle = CAM_PITCH + theta_y
                    if ground_angle <= 0:
                        continue

                    forward_dist = curr_alt / math.tan(ground_angle) # using curr_alt instead of fixed DRONE_ALT
                    lateral_dist = forward_dist * math.tan(theta_x)

                    R = 6378137.0
                    dlat = (forward_dist / R) * (180 / math.pi)
                    dlon = (lateral_dist / (R * math.cos(math.radians(curr_lat)))) * (180 / math.pi)

                    human_lat = curr_lat + dlat
                    human_lon = curr_lon + dlon

                    cell = (
                        int(forward_dist / CELL_SIZE_M),
                        int(lateral_dist / CELL_SIZE_M)
                    )

                    seen_cells.add(cell)
                    self.candidate_counter[cell] = self.candidate_counter.get(cell, 0) + 1

                    # ---------- 7-FRAME CONFIRMATION ----------
                    if self.candidate_counter[cell] == FRAME_CONFIRM:

                        assigned_id = None
                        for hmn in self.humans:
                            if self.haversine_m(hmn["lat"], hmn["lon"], human_lat, human_lon) < DUPLICATE_RADIUS_M:
                                assigned_id = hmn["id"]
                                break

                        if assigned_id is None:
                            assigned_id = self.next_human_id
                            self.humans.append({
                                "id": assigned_id,
                                "lat": human_lat,
                                "lon": human_lon
                            })
                            self.next_human_id += 1

                        # ---------- SAVE ONLY ONCE PER ID ----------
                        if assigned_id not in self.saved_ids:
                            # Using time module instead of datetime as requested
                            ts = time.strftime("%Y%m%d_%H%M%S")

                            img_path = os.path.join(self.IMG_DIR, f"human_{assigned_id}_{ts}.jpg")
                            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                            cv2.imwrite(img_path, frame)

                            with open(self.CSV_PATH, "a", newline="") as f:
                                writer = csv.writer(f)
                                writer.writerow([
                                    ts,
                                    assigned_id,
                                    round(human_lat, 7),
                                    round(human_lon, 7)
                                ])

                            self.saved_ids.add(assigned_id)
                            logging.info(f"âœ… SAVED HUMAN ID {assigned_id} (conf={conf:.2f})")
                            
                            # Log success and update batch info
                            self.ids_in_current_batch += 1
                            logging.info(f"Current batch count: {self.ids_in_current_batch}")
                            
                            # Trigger MQTT Transfer if Batch Complete (5 detected)
                            # Or if user wants it sent immediately? User said "batch logic" in past, but "The code isn't sending" implies expectation.
                            # Original code had batch size 5. I will stick to that unless 5 is too high for this test.
                            # But user might be testing with < 5 humans.
                            # I'll stick to 5 as per original survey.py I saw earlier.
                            
                            if self.ids_in_current_batch >= 5:
                                logging.info(f"Batch {self.batch_id} complete (5 ids). Triggering MQTT Transfer...")
                                try:
                                    # Send this specific batch file... WAIT.
                                    # survey_final.py logic appends to "final_human_coordinates.csv".
                                    # It does NOT create batch files like "human_locations_1.csv".
                                    # The original survey.py created separate batch files.
                                    # The user said "output like... survey_final.py", so single CSV.
                                    # So now I need to send the SINGLE CSV? Or pieces of it?
                                    # If I just send the single CSV repeatedly, it might work but is inefficient.
                                    # The original `mqtt_transfer.py` takes a file.
                                    # I will send the main CSV file every 5 detections.
                                    
                                    log_filename = f"mqtt_log_{self.batch_id}.txt"
                                    log_file = open(log_filename, "w")
                                    subprocess.Popen(["python3", "mqtt_transfer.py", "--mode", "sender", "--file", self.CSV_PATH], stdout=log_file, stderr=log_file)
                                    logging.info(f"Transmitting {self.CSV_PATH} in background (logs in {log_filename})...")
                                    
                                    self.batch_id += 1
                                    self.ids_in_current_batch = 0
                                    
                                except Exception as e:
                                    logging.error(f"Failed to start MQTT sender: {e}")

            self.candidate_counter = {k: v for k, v in self.candidate_counter.items() if k in seen_cells}

            # Optional: Display for debugging if headful
            # cv2.imshow("Human Detection", frame)
            # if cv2.waitKey(1) & 0xFF == ord('q'):
            #    break

        cap.release()

    def monitor_keyboard(self):
        """
        Monitors for 'SPACE' key press to trigger RTL.
        """
        logging.info("Keyboard monitor started. Press SPACE for RTL.")
        
        while not self.stop_requested:
            try:
                if select.select([sys.stdin], [], [], 0.1)[0]:
                    # Save terminal settings
                    old_settings = termios.tcgetattr(sys.stdin)
                    try:
                        tty.setcbreak(sys.stdin.fileno())
                        key = sys.stdin.read(1)
                        if key == ' ':
                            logging.warning("SPACE pressed! Triggering RTL...")
                            self.set_mode("RTL")
                            self.stop_requested = True
                    finally:
                        termios.tcsetattr(sys.stdin, termios.TCSADRAIN, old_settings)
            except Exception:
                pass
            time.sleep(0.1)

    def set_kml_file(self, kml_path):
        self.kml_file = kml_path

    # ---------------------------
    # KML Parsing
    # ---------------------------
    def parse_kml_coordinates(self, kml_path):
        """
        Parses KML file to extract polygon coordinates.
        Supports standard KML (lon,lat) and heuristic check.
        Returns list of (lat, lon).
        """
        if not os.path.exists(kml_path):
            logging.error(f"KML file not found: {kml_path}")
            return []

        try:
            tree = ET.parse(kml_path)
            root = tree.getroot()
            # Namespace handling
            ns = {'kml': 'http://www.opengis.net/kml/2.2'}
            # Find coordinates in Polygon/outerBoundaryIs/LinearRing/coordinates
            # This path works for the provided examples.
            coords_text = None
            for coords_node in root.findall('.//kml:coordinates', ns):
                coords_text = coords_node.text
                break
            
            if not coords_text:
                # Try without namespace if failed
                 for coords_node in root.findall('.//coordinates'):
                    coords_text = coords_node.text
                    break

            if not coords_text:
                logging.error("No coordinates found in KML.")
                return []

            points = []
            # Split by whitespace
            raw_points = coords_text.strip().split()
            for p in raw_points:
                # KML format: lon,lat,alt
                parts = p.split(',')
                if len(parts) >= 2:
                    p1 = float(parts[0])
                    p2 = float(parts[1])
                    
                    # Heuristic: Latitude is always [-90, 90]. Longitude [-180, 180].
                    # Standard KML is lon, lat.
                    # If the first number is > 90 or < -90, it MUST be lon.
                    # If the second number is > 90 or < -90, it MUST be lon (and first is lat).
                    # If both are within range, we assume standard lon, lat unless we have reason not to.
                    
                    lat, lon = 0.0, 0.0
                    
                    if abs(p2) > 90:
                        # p2 is definitely lon? No, lat cant be > 90.
                        # Wait, if p2 > 90, it CANNOT be lat. So p2=lon, p1=lat.
                        # But wait, standard is lon,lat => p1=lon, p2=lat.
                        # If p2 > 90, then p2 is invalid latitude.
                        pass
                        
                    # Let's check ranges.
                    is_p1_lat_candidate = -90 <= p1 <= 90
                    is_p2_lat_candidate = -90 <= p2 <= 90
                    
                    if is_p1_lat_candidate and not is_p2_lat_candidate:
                        # p1 is lat, p2 is lon (Non-standard "lat,lon")
                        lat, lon = p1, p2
                    elif not is_p1_lat_candidate and is_p2_lat_candidate:
                        # p1 is lon, p2 is lat (Standard "lon,lat")
                        lat, lon = p2, p1
                    else:
                        # Both could be lat? Assume Standard lon, lat
                        lat, lon = p2, p1
                        
                    points.append((lat, lon))
            
            logging.info(f"Parsed {len(points)} points from KML.")
            return points

        except Exception as e:
            logging.error(f"Failed to parse KML: {e}")
            return []

    # ---------------------------
    # Ray Casting Algo
    # ---------------------------
    def is_point_in_polygon(self, lat, lon, polygon):
        """
        Ray-casting algorithm to find if (lat, lon) is inside polygon.
        Polygon is list of (lat, lon).
        """
        inside = False
        n = len(polygon)
        p1lat, p1lon = polygon[0]
        for i in range(1, n + 1):
            p2lat, p2lon = polygon[i % n]
            if self._target_lat_intersects_edge(lat, lon, p1lat, p1lon, p2lat, p2lon):
               inside = not inside
            p1lat, p1lon = p2lat, p2lon
        return inside

    def _target_lat_intersects_edge(self, lat, lon, p1lat, p1lon, p2lat, p2lon):
        # Check if ray from (lat, lon) to (lat, +inf) crosses edge (p1, p2)
        # We use latitude as the Y-axis, Longitude as X-axis just for mental mapping, 
        # but standard algorithm:
        # Cross if p1lon > lon != p2lon > lon (one point to right) ... wait.
        # Ray casting: usually cast horizontal ray to right.
        # lat is Y, lon is X.
        # Check if point.y is between p1.y and p2.y
        
        if min(p1lat, p2lat) < lat <= max(p1lat, p2lat):
            # find x intersection
            if p1lat != p2lat:
                x_inters = (lat - p1lat) * (p2lon - p1lon) / (p2lat - p1lat) + p1lon
            else:
                x_inters = p2lon # Horizontal line?
                
            if p1lon == p2lon:
                 x_inters = p1lon
                 
            if lon < x_inters:
                return True
        return False

    # ---------------------------
    # Grid generation
    # ---------------------------
    def generate_grid_from_polygon(self, polygon, spacing):
        """
        Generates vertical lawn-mower pattern inside the polygon.
        """
        if not polygon:
            return []
            
        lats = [p[0] for p in polygon]
        lons = [p[1] for p in polygon]
        
        min_lat, max_lat = min(lats), max(lats)
        min_lon, max_lon = min(lons), max(lons)
        
        waypoints = []
        # Start from left (min_lon) to right
        curr_lon = min_lon
        reverse = False
        
        while curr_lon <= max_lon:
            col_points = []
            # Scan latitude from max to min
            curr_lat = max_lat
            while curr_lat >= min_lat:
                if self.is_point_in_polygon(curr_lat, curr_lon, polygon):
                    col_points.append((curr_lat, curr_lon))
                curr_lat -= spacing
            
            if col_points:
                # User Request: Only start and end points of the line
                if len(col_points) > 1:
                    col_points = [col_points[0], col_points[-1]]
                
                if reverse:
                    col_points.reverse()
                waypoints.extend(col_points)
                reverse = not reverse
                
            curr_lon += spacing
            
        return waypoints

    # ---------------------------
    # Utility: haversine distance (meters)
    # ---------------------------
    def haversine_m(self, lat1, lon1, lat2, lon2):
        # returns distance in meters between two lat/lon points
        R = 6371000.0  # Earth radius meters
        phi1 = math.radians(lat1)
        phi2 = math.radians(lat2)
        dphi = math.radians(lat2 - lat1)
        dlambda = math.radians(lon2 - lon1)
        a = math.sin(dphi/2.0)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlambda/2.0)**2
        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
        return R * c

    # ---------------------------
    # Read last known global position (non-blocking timeout)
    # ---------------------------
    # ---------------------------
    # Read last known global position (from cache)
    # ---------------------------
    def get_current_global_position(self, timeout=1.0):
        """
        Returns tuple (lat_deg, lon_deg, alt_m) or None if no data.
        Uses cached data from listener.
        """
        start = time.time()
        while time.time() - start < timeout:
            with self.mutex:
                if self.current_lat is not None:
                    return (self.current_lat, self.current_lon, self.current_alt)
            time.sleep(0.05)
        return None

    # ---------------------------
    # Speed control
    # ---------------------------
    def set_speed(self, speed_m_s):
        """
        Sets the vehicle speed using WPNAV_SPEED parameter.
        WPNAV_SPEED is in cm/s.
        """
        try:
            # WPNAV_SPEED is in cm/s
            speed_cm_s = int(speed_m_s * 100)
            
            self.master.mav.param_set_send(
                self.master.target_system,
                self.master.target_component,
                b'WPNAV_SPEED',
                speed_cm_s,
                mavutil.mavlink.MAV_PARAM_TYPE_INT32
            )
            logging.info(f"WPNAV_SPEED set to {speed_cm_s} cm/s ({speed_m_s} m/s)")
        except Exception as e:
            logging.error(f"Failed to set speed: {e}")

    # ---------------------------
    # Send a guided set-position command (global)
    # ---------------------------
    def send_guided_position(self, lat, lon, alt):
        """
        Robust send using SET_POSITION_TARGET_GLOBAL_INT that tries signed first,
        then unsigned (two's-complement) if packing complains.
        Works for pymavlink variants that pack lat/lon as 'i' or 'I'.
        """
        # prepare representations
        signed_lat = int(round(lat * 1e7))
        signed_lon = int(round(lon * 1e7))
        unsigned_lat = signed_lat & 0xFFFFFFFF
        unsigned_lon = signed_lon & 0xFFFFFFFF

        # time_boot_ms as uint32
        # Use 0 as we don't track boot time, ensuring it's ignored/handled correctly
        time_ms = 0

        # frame: prefer integer frame if available
        if hasattr(mavutil.mavlink, 'MAV_FRAME_GLOBAL_RELATIVE_ALT_INT'):
            frame = mavutil.mavlink.MAV_FRAME_GLOBAL_RELATIVE_ALT_INT
        else:
            frame = mavutil.mavlink.MAV_FRAME_GLOBAL_RELATIVE_ALT

        # position-only type_mask
        type_mask = 0b0000111111111000

        # helper to call the pymavlink send and wrap errors
        def _call_setpos(lat_val, lon_val):
            self.master.mav.set_position_target_global_int_send(
                time_ms,
                self.master.target_system,
                self.master.target_component,
                frame,
                type_mask,
                lat_val,
                lon_val,
                float(alt),
                0, 0, 0,            # vx, vy, vz
                0, 0, 0,            # afx, afy, afz
                float('nan'),       # yaw (ignored by mask)
                0                   # yaw_rate
            )

        # attempt signed first (natural)
        try:
            _call_setpos(signed_lat, signed_lon)
            # Log reduced to debug to avoid spamming if frequent, but here it's per waypoint
            logging.debug(
                f"Sent guided position (signed int) -> {lat:.6f},{lon:.6f},{alt:.1f}"
            )
            return
        except Exception as e_signed:
            s_err = str(e_signed)
            # if error indicates unsigned packing required, try unsigned
            if "'I' format" in s_err or "unsigned" in s_err or "requires 0 <=" in s_err:
                try:
                    _call_setpos(unsigned_lat, unsigned_lon)
                    logging.debug(
                        f"Sent guided position (unsigned int fallback) -> {lat:.6f},{lon:.6f},{alt:.1f}"
                    )
                    return
                except Exception as e_unsigned:
                    logging.error(f"Unsigned fallback failed: {e_unsigned}")
                    return

        # If we reached here it means signed attempt failed but didn't indicate unsigned; try unsigned anyway
        try:
            _call_setpos(unsigned_lat, unsigned_lon)
            return
        except Exception as e_final:
            logging.error(f"Final unsigned retry failed: {e_final}")
            return

    # ---------------------------
    # Mode & arm helpers
    # ---------------------------
    def set_mode(self, mode):
        # uses mavutil.set_mode helper
        try:
            self.master.set_mode(mode)
            logging.info(f"Set mode to {mode}")
            time.sleep(1.0)
        except Exception as e:
            logging.error(f"Failed to set mode {mode}: {e}")

    def arm(self):
        try:
            self.master.arducopter_arm()
            logging.info("Arming command sent")
            time.sleep(2.0) # Simple wait since listener consumes heartbeats
            # In a robust system, we would check self.current_mode from listener
        except Exception as e:
            logging.error(f"Failed to arm: {e}")

    def takeoff(self, target_alt_m):
        """
        Sends a NAV_TAKEOFF command in GUIDED to request takeoff.
        """
        try:
            self.master.mav.command_long_send(
                self.master.target_system,
                self.master.target_component,
                mavutil.mavlink.MAV_CMD_NAV_TAKEOFF,
                0,
                0, 0, 0, 0, 0, 0,
                float(target_alt_m)
            )
            logging.info(f"Takeoff command sent to {target_alt_m} m")
        except Exception as e:
            logging.error(f"Failed to send takeoff: {e}")


    # ---------------------------
    # Mission runner (background)
    # ---------------------------
    def load_and_run_mission(self):
        """
        Generate grid -> switch to GUIDED -> arm -> takeoff -> iterate waypoints -> send guided commands one-by-one
        """
        if self.kml_file:
            self.polygon_coords = self.parse_kml_coordinates(self.kml_file)
            
        if not self.polygon_coords:
             logging.error("No polygon coordinates available. Cannot generate grid.")
             return

        # generate grid
        grid = self.generate_grid_from_polygon(self.polygon_coords, self.spacing)
        if not grid:
            logging.error("No waypoints generated.")
            return

        logging.info(f"Generated {len(grid)} waypoints.")


        # switch to GUIDED
        self.set_mode("GUIDED")

        # arm
        self.arm()
        
        # Set speed
        self.set_speed(self.speed)


        # (Optional) read one position message before takeoff
        try:
            alt_msg = self.master.recv_match(
                type='GLOBAL_POSITION_INT',
                blocking=True,
                timeout=5.0
            )
            if alt_msg:
                init_alt = float(alt_msg.relative_alt) / 1000.0
                logging.info(f"Initial altitude before takeoff: {init_alt:.1f} m")
        except Exception as e:
            logging.warning(f"Failed to read initial altitude: {e}")

        # takeoff
        self.takeoff(self.altitude)

        # Wait until we are near the target altitude (within 1 m), up to some timeout
        logging.info("Waiting to reach takeoff altitude...")
        start = time.time()
        while time.time() - start < 60 and not self.stop_requested:
            pos = self.get_current_global_position(timeout=1.0)
            if pos is not None:
                _, _, cur_alt = pos
                logging.info(f"Current altitude: {cur_alt:.1f} m")
                if abs(cur_alt - self.altitude) <= 2.0:
                    logging.info("Reached takeoff altitude.")
                    break
            else:
                logging.debug("No position while waiting for takeoff altitude.")
            time.sleep(0.02)

        # iterate waypoints
        for idx, (lat, lon) in enumerate(grid):
            if self.stop_requested:
                logging.info("Stop requested; aborting waypoint loop.")
                return

            logging.info(
                f"Sending waypoint {idx+1}/{len(grid)} -> lat:{lat:.6f}, lon:{lon:.6f}"
            )
            
            # START DETECTION AFTER REACHING 1st WAYPOINT (i.e. heading to 2nd)
            # OR start immediately? User said "When drone reaches first waypoint, start detection"
            # So if idx == 0 (first WP reached loop end), start it.
            # But here we are SENDING WP 1.
            # Let's start it after the first waypoint is REACHED.
            # See logic below 'reached = True'.

            # wait until inside accept radius or timeout
            start = time.time()
            reached = False
            while time.time() - start < self.waypoint_timeout_s and not self.stop_requested:
                


                if self.stop_requested:
                    break

                # Resend command periodically (1Hz) to prevent timeout and handle packet loss
                self.send_guided_position(lat, lon, self.altitude)
                
                cur = self.get_current_global_position(timeout=1.0)
                if cur is None:
                    logging.debug("No position message received while waiting.")
                    continue

                cur_lat, cur_lon, cur_alt = cur
                d = self.haversine_m(cur_lat, cur_lon, lat, lon)
                logging.info(
                    f"Distance to WP: {d:.1f} m | current alt: {cur_alt:.1f} m"
                )

                if d <= self.accept_radius_m:
                    reached = True
                    logging.info(
                        f"Waypoint {idx+1} reached (d={d:.1f} m)."
                    )
                    
                    # START DETECTION if this was the First Waypoint
                    if idx == 0:
                        logging.info("Reached 1st Waypoint. Starting Human Detection...")
                        self.start_detection()
                        
                    break
                    
                time.sleep(0.5)

            if not reached:
                logging.warning(
                    f"Timeout waiting for waypoint {idx+1}. Continuing to next waypoint."
                )

        logging.info("All waypoints processed (or mission ended).")
        
        # Mission Complete -> RTL
        if not self.stop_requested:
            logging.info("Mission Complete. Triggering RTL.")
            self.set_mode("RTL")


def main(args=None):
    # Configure logging
    log_filename = f"mission_log_{time.strftime('%Y%m%d_%H%M%S')}.txt"
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(message)s',
        handlers=[
            logging.FileHandler(log_filename),
            logging.StreamHandler(sys.stdout)
        ]
    )
    logging.info(f"Logging to file: {log_filename}")

    parser = argparse.ArgumentParser(description='Grid Survey Node')
    # parser.add_argument('--kml', type=str, default='demo_survey_area_new.kml', help='Path to KML file')
    parser.add_argument('--connect', type=str, default='/dev/ttyACM0', help='MAVLink connection string')
    parser.add_argument('--connect', type=str, default='udp:127.0.0.1:14551', help='MAVLink connection string')
    parser.add_argument('--speed', type=float, default=5.0, help='Drone speed in m/s')
    
    parsed = parser.parse_args()

    node = GridSurveyNode(parsed.connect)
    
    # Configure node
    node.set_kml_file(parsed.kml)
    node.speed = parsed.speed
    
    # Update connection if needed (currently hardcoded in init)
    # Re-connect logic would go here if we updated __init__
    
    logging.info(f"Using KML: {node.kml_file}")
    logging.info(f"Target Speed: {node.speed} m/s")

    # Start mission
    node.start_mission()

    try:
        # Main loop to keep the script running
        while not node.stop_requested:
            time.sleep(1.0)
    except KeyboardInterrupt:
        logging.info("KeyboardInterrupt detected in main; exiting.")
    finally:
        # Simple cleanup if needed
        pass


if __name__ == '__main__':
    main()





'''
Bugs:

*1. No waypoint control speed is set; vehicle may move too fast or too slow between waypoints.
*2. No handling of vehicle disconnection or loss of MAVLink link.
*3. No retries for failed MAVLink commands beyond basic error logging.
*4. No logging of mission progress to file; all logs go to console only.
*5. Altitude during takeoff is not monitored beyond a simple wait loop.
*6. Time synchronization issues may arise if system time changes during mission.
*7. No complex error recovery; mission aborts on first critical failure.

'''
